# ============================================================================
# VISTA Personal AI RAG System - Production Environment Configuration
# ============================================================================
# This file serves as a template for production environment variables.
# Copy this file to .env.production and fill in all required values.
# NEVER commit actual secrets to version control.
#
# Validation Rules:
# - All REQUIRED variables must be set before deployment
# - API keys must be valid and have appropriate permissions
# - URLs must be valid HTTPS URLs in production
# - CORS origins must be valid URLs
# - Numeric values must be positive integers
# ============================================================================

# ============================================================================
# ENVIRONMENT CONFIGURATION
# ============================================================================
# Environment mode: must be 'production' for production deployments
# Validation: Must be exactly 'production'
ENVIRONMENT=production

# Server port: port number for the API server
# Validation: Must be a positive integer (1-65535), typically 8000
PORT=8000

# Log level: controls verbosity of logging
# Validation: Must be one of: debug, info, warning, error, critical
LOG_LEVEL=info

# ============================================================================
# LLM PROVIDER CONFIGURATION (REQUIRED)
# ============================================================================
# LLM Provider: which AI provider to use
# Validation: Must be exactly 'openai' or 'gemini'
# Note: Only the API key for the selected provider needs to be set
LLM_PROVIDER=gemini

# OpenAI Configuration (REQUIRED if LLM_PROVIDER=openai)
# Validation: Must be a valid OpenAI API key starting with 'sk-'
# Format: sk-proj-[alphanumeric characters]
OPENAI_API_KEY=sk-proj-your_openai_api_key_here

# OpenAI Model: which OpenAI model to use
# Validation: Must be a valid OpenAI model name
# Examples: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
OPENAI_MODEL=gpt-4o-mini

# Gemini Configuration (REQUIRED if LLM_PROVIDER=gemini)
# Validation: Must be a valid Google Gemini API key
# Format: AIza[alphanumeric characters]
GEMINI_API_KEY=AIza_your_gemini_api_key_here

# Gemini Model: which Gemini model to use
# Validation: Must be a valid Gemini model name
# Examples: gemini-2.5-flash, gemini-1.5-pro, gemini-1.5-flash
GEMINI_MODEL=gemini-2.5-flash

# ============================================================================
# SECURITY CONFIGURATION (REQUIRED)
# ============================================================================
# CORS Origins: comma-separated list of allowed origins for API requests
# Validation: Must be valid HTTPS URLs in production (no http://)
# Format: https://domain.com,https://api.domain.com
# Note: Each origin must be a complete URL with protocol
ALLOWED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com

# ============================================================================
# FRONTEND CONFIGURATION (REQUIRED)
# ============================================================================
# Frontend API URL: URL where frontend can reach the backend API
# Validation: Must be a valid HTTPS URL in production
# Format: https://api.yourdomain.com or https://yourdomain.com/api
NEXT_PUBLIC_VISTA_API_URL=https://api.yourdomain.com

# GitHub URL: link to GitHub profile (optional but recommended)
# Validation: Must be a valid GitHub profile URL
# Format: https://github.com/username
NEXT_PUBLIC_GITHUB_URL=https://github.com/yourusername

# LinkedIn URL: link to LinkedIn profile (optional but recommended)
# Validation: Must be a valid LinkedIn profile URL
# Format: https://www.linkedin.com/in/yourprofile/
NEXT_PUBLIC_LINKEDIN_URL=https://www.linkedin.com/in/yourprofile/

# Email: contact email address (optional but recommended)
# Validation: Must be a valid email address
# Format: user@example.com
NEXT_PUBLIC_EMAIL=your.email@example.com

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================
# Data Directory: path to directory containing source documents
# Validation: Must be a valid directory path with read permissions
# Default: ./data
DATA_DIRECTORY=./data

# Persist Directory: path to directory for ChromaDB persistence
# Validation: Must be a valid directory path with write permissions
# Default: ./chroma_db
# Note: This directory must be on persistent storage (volume/EBS/etc)
PERSIST_DIRECTORY=./chroma_db

# ============================================================================
# CHUNKING CONFIGURATION (Optional - defaults provided)
# ============================================================================
# Chunk Size: maximum size of text chunks in characters
# Validation: Must be a positive integer, typically 300-1000
# Default: 500
CHUNK_SIZE=500

# Chunk Overlap: number of overlapping characters between chunks
# Validation: Must be a non-negative integer less than CHUNK_SIZE
# Default: 50
CHUNK_OVERLAP=50

# ============================================================================
# EMBEDDING CONFIGURATION (Optional - defaults provided)
# ============================================================================
# Embedding Model: sentence-transformers model for embeddings
# Validation: Must be a valid sentence-transformers model name
# Default: all-MiniLM-L6-v2
# Note: Model will be downloaded on first use
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================================================
# QUERY CONFIGURATION (Optional - defaults provided)
# ============================================================================
# Max Context Tokens: maximum tokens for context sent to LLM
# Validation: Must be a positive integer, typically 2000-4000
# Default: 3000
MAX_CONTEXT_TOKENS=3000

# Max Response Tokens: maximum tokens for LLM response
# Validation: Must be a positive integer, typically 500-2000
# Default: 500
MAX_RESPONSE_TOKENS=500

# Top K Results: number of similar documents to retrieve
# Validation: Must be a positive integer, typically 3-10
# Default: 5
TOP_K_RESULTS=5

# ============================================================================
# RETRY CONFIGURATION (Optional - defaults provided)
# ============================================================================
# Max Retries: maximum number of retry attempts for API calls
# Validation: Must be a non-negative integer, typically 2-5
# Default: 3
MAX_RETRIES=3

# ============================================================================
# DEPLOYMENT NOTES
# ============================================================================
# 1. REQUIRED VARIABLES:
#    - ENVIRONMENT (must be 'production')
#    - LLM_PROVIDER (must be 'openai' or 'gemini')
#    - API key for selected provider (OPENAI_API_KEY or GEMINI_API_KEY)
#    - ALLOWED_ORIGINS (must be valid HTTPS URLs)
#    - NEXT_PUBLIC_VISTA_API_URL (must be valid HTTPS URL)
#
# 2. SECURITY BEST PRACTICES:
#    - Never commit this file with actual secrets
#    - Use a secrets management system (AWS Secrets Manager, HashiCorp Vault, etc.)
#    - Rotate API keys regularly
#    - Use HTTPS for all URLs in production
#    - Restrict CORS origins to only necessary domains
#
# 3. VALIDATION:
#    - All required variables must be set before deployment
#    - API keys must be validated before deployment
#    - CORS origins must be valid HTTPS URLs
#    - All numeric values must be positive integers
#
# 4. PERSISTENCE:
#    - PERSIST_DIRECTORY must be on persistent storage
#    - For Docker: use a volume mount
#    - For Kubernetes: use a PersistentVolume
#    - For AWS: use EBS volume or S3
#
# 5. MONITORING:
#    - Monitor API key usage and quotas
#    - Monitor database size and performance
#    - Monitor error rates and response times
#    - Set up alerts for critical errors
# ============================================================================
